{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções Individuais que suportam o texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessar_texto(texto):\n",
    "    texto = texto.lower()\n",
    "    delimitadores = '[_]|[ ]|[!]|[; ]|[, ]|[\\r]|[\\n]|[.]'\n",
    "    doc = re.split(delimitadores, texto)\n",
    "    return [i for i in doc if i != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['era',\n",
       " 'uma',\n",
       " 'vez',\n",
       " 'um',\n",
       " 'rei',\n",
       " 'que',\n",
       " 'vivia',\n",
       " 'em',\n",
       " 'um',\n",
       " 'castelo',\n",
       " 'o',\n",
       " 'castelo',\n",
       " 'era',\n",
       " 'muito',\n",
       " 'grande',\n",
       " 'e',\n",
       " 'tinha',\n",
       " 'várias',\n",
       " 'torres']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = \"Era uma vez um rei que vivia em um castelo. O castelo era muito grande e tinha várias torres.\"\n",
    "preprocessar_texto(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_modelo_ngram(documento, n):\n",
    "    transicoes = {}\n",
    "\n",
    "    for i in range(len(documento) - n + 1):\n",
    "        ngram = tuple(documento[i:i+n-1])\n",
    "        proxima_palavra = documento[i+n-1]\n",
    "        \n",
    "        if ngram not in transicoes:\n",
    "            transicoes[ngram] = []\n",
    "        \n",
    "        transicoes[ngram].append(proxima_palavra)\n",
    "    \n",
    "    return transicoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('era',): ['uma', 'muito'],\n",
       " ('uma',): ['vez'],\n",
       " ('vez',): ['um'],\n",
       " ('um',): ['rei', 'castelo'],\n",
       " ('rei',): ['que'],\n",
       " ('que',): ['vivia'],\n",
       " ('vivia',): ['em'],\n",
       " ('em',): ['um'],\n",
       " ('castelo',): ['o', 'era'],\n",
       " ('o',): ['castelo'],\n",
       " ('muito',): ['grande'],\n",
       " ('grande',): ['e'],\n",
       " ('e',): ['tinha'],\n",
       " ('tinha',): ['várias'],\n",
       " ('várias',): ['torres']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criar_modelo_ngram(preprocessar_texto(texto), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "def gerar_texto(documento, n, frase_inicial, n_max_palavras):\n",
    "    \n",
    "    inicio = preprocessar_texto(frase_inicial)\n",
    "    atual = tuple(inicio[-(n-1):])\n",
    "    resultado = inicio  \n",
    "\n",
    "    while len(resultado)<n_max_palavras:\n",
    "        possiveis_proximas_palavras = documento.get(atual, [])\n",
    "        if not possiveis_proximas_palavras:\n",
    "            break\n",
    "        \n",
    "        contagem = Counter(possiveis_proximas_palavras)    \n",
    "        total = sum(contagem.values())\n",
    "        \n",
    "        probabilidades = {palavra: cont/total for palavra, cont in contagem.items()}\n",
    "        \n",
    "        prob_max = max(probabilidades.values())\n",
    "        mais_provavel = [palavra for palavra, prob in probabilidades.items() if prob == prob_max]\n",
    "        \n",
    "        proxima_palavra = random.choice(mais_provavel)\n",
    "        \n",
    "        resultado.append(proxima_palavra)          \n",
    "        atual = tuple(resultado[-(n-1):])\n",
    "    \n",
    "    return \" \".join(resultado) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'era uma vez um castelo era muito grande e tinha várias torres'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = criar_modelo_ngram(preprocessar_texto(texto), 2)\n",
    "gerar_texto(documento=t, n=2, frase_inicial=\"era uma vez\", n_max_palavras=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ngram_model():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def preprocessar_texto(self, texto):\n",
    "        import re\n",
    "        return re.findall(r'\\w+|[.,;!]', texto.lower())\n",
    "    \n",
    "    def criar_modelo_ngram(self, documento, n):\n",
    "        transicoes = {}\n",
    "\n",
    "        for i in range(len(documento) - n + 1):\n",
    "            ngram = tuple(documento[i:i+n-1])\n",
    "            proxima_palavra = documento[i+n-1]\n",
    "            \n",
    "            if ngram not in transicoes:\n",
    "                transicoes[ngram] = []\n",
    "            \n",
    "            transicoes[ngram].append(proxima_palavra)\n",
    "        \n",
    "        return transicoes\n",
    "    \n",
    "    def maiuscula(text):\n",
    "        result = []\n",
    "        capitalize_next = False \n",
    "        for char in text:\n",
    "            if capitalize_next and char.isalpha(): \n",
    "                result.append(char.upper())  \n",
    "                capitalize_next = False\n",
    "            else:\n",
    "                result.append(char)\n",
    "            if char in ['.', '', \"!\", \"\\n\", \":\", \"?\"]:  \n",
    "                capitalize_next = True\n",
    "        return result[0].upper()+''.join(result[1:])   \n",
    "\n",
    "\n",
    "    def gerar_texto(self, documento, n, frase_inicial, max_repeats=1, n_max_palavras=100):    \n",
    "        from collections import Counter\n",
    "        import random  \n",
    "        \n",
    "        inicio = preprocessar_texto(frase_inicial)\n",
    "        atual = tuple(inicio[-(n-1):])\n",
    "        resultado = inicio  \n",
    "        ngrams_usado = Counter()\n",
    "\n",
    "        while len(resultado)<n_max_palavras:\n",
    "            possiveis_proximas_palavras = documento.get(atual, [])\n",
    "            if not possiveis_proximas_palavras:\n",
    "                continue\n",
    "            \n",
    "            contagem = Counter(possiveis_proximas_palavras)    \n",
    "            total = sum(contagem.values())\n",
    "            \n",
    "            probabilidades = {palavra: cont/total for palavra, cont in contagem.items()}\n",
    "            \n",
    "            prob_max = max(probabilidades.values())\n",
    "            mais_provavel = [palavra for palavra, prob in probabilidades.items() if prob == prob_max]\n",
    "            \n",
    "            proxima_palavra = random.choice(mais_provavel)\n",
    "\n",
    "            if ngrams_usado[atual] >= max_repeats:\n",
    "                possiveis_proximas_palavras = [word for word in possiveis_proximas_palavras if word != proxima_palavra]\n",
    "                if possiveis_proximas_palavras:\n",
    "                    proxima_palavra = random.choice(possiveis_proximas_palavras)\n",
    "            \n",
    "            resultado.append(proxima_palavra)          \n",
    "            atual = tuple(resultado[-(n-1):])\n",
    "            ngrams_usado[atual]+=1\n",
    "        \n",
    "        return self.maiuscula(\" \".join(resultado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importação e teste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemplo de texto:\n",
      " us desejos, e que produzissem folhas e frutos como queriam; pois as entesposas desejavam a ordem, muita ordem, e paz (que para elas queria dizer que as coisas deviam permanecer como elas as tinham colocado). Então as entesposas fizeram jardim nos quais pu\n"
     ]
    }
   ],
   "source": [
    "# Importar textos\n",
    "folder = 'hiddendata/'\n",
    "with open(folder+'01 - A Sociedade do Anel.txt', 'r', encoding=\"utf8\") as f:\n",
    "    asda=f.read()\n",
    "with open(folder+'02 - As Duas Torres.txt', 'r', encoding=\"utf8\") as f:\n",
    "    adt=f.read()\n",
    "with open(folder+'03 - O Retorno do Rei.txt', 'r', encoding=\"utf8\") as f:\n",
    "    ordr=f.read()\n",
    "text = asda + adt + ordr\n",
    "nchars = int(random.random()*len(text))\n",
    "sda = asda + adt + ordr\n",
    "print(\"\\nExemplo de texto:\\n\",text[nchars:nchars+255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Havia uma consoante longa estrada passaram como coisas de valfenda teria plantas mais seca a canção que passavam de tristeza — vamos ficar aqui onde estão pesados do perigo desnecessário é quase tão bem fechadas qualquer coisa foi realmente achou fácil contra o tamanho medo de gandalf pegou-o em sua garganta e começou e todas aquelas barbas ou até lá fora colocado na mão cair no tesouro permaneça sobre seus pais das palavras precipitadas a escuridão onde morei mas ele mas os olhos quando tropeçava ao piquenique? — E em quando erguendo à sua revelia e robustas alguns pareciam constrangidos'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = criar_modelo_ngram(preprocessar_texto(sda), 2)\n",
    "ngram_model().gerar_texto(documento=t, n=2, frase_inicial=\"Havia\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
